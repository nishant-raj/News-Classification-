{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News_category_prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "R2Xd3KvAY0m8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "  !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "  !apt-get update -qq 2>&1 > /dev/null\n",
        "  !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  creds = GoogleCredentials.get_application_default()\n",
        "  import getpass\n",
        "  !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "  vcode = getpass.getpass()\n",
        "  !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_dQUTPGZRlk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QnNSbvkUZR2d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd drive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rOLUOwa9ZyoY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd News categorization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgWOjjs-Y0nt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "data=pd.read_json(\"News_Category_Dataset.json\",lines=True)\n",
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmdMHAPehuJK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data.sample(10000, random_state=42)\n",
        "data.reset_index(inplace=True, drop=True)\n",
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2OPwvkNaphJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.groupby(by='category').size()/10000*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wS_QnU82ZxEi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(35,7))\n",
        "sns.countplot(x = 'category', data = data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbPBLrKCd2G1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
        "data['category'].value_counts().plot.pie( autopct = '%1.1f%%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IWrbE-1YY0oO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# merge headline column and short_description to get one extra feature named important feature\n",
        "\n",
        "data['imp'] = data['short_description'].astype(str) + data['headline']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8fL7kLZY0ob",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import required library \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.display.max_columns = 200\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "#from nltk.corpus import stopwords\n",
        "#stop = set(stopwords.words('english'))\n",
        "from string import punctuation\n",
        "\n",
        "from collections import Counter\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "tqdm_notebook().pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83VLqHINY0ow",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# shape of dataset\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zlVGRk7RY0pK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove duplicates and null value from imp column\n",
        "\n",
        "data = data.drop_duplicates('imp')\n",
        "data = data[~data['imp'].isnull()]\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "soNgNdmRY0pd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# these are most frequent stop words here used my own generated stopwords rather than predefied NLP having very less no. of stop words approx 150\n",
        "# stopwords.txt is imported drom my local system rather than python pre-defined \n",
        "\n",
        "stop_words = []\n",
        "f = open('stopwords.txt', 'r')\n",
        "for l in f.readlines():\n",
        "    stop_words.append(l.replace('\\n', ''))\n",
        "additional_stop_words = ['t', 'will']\n",
        "stop_words += additional_stop_words\n",
        "\n",
        "print(len(stop_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zoWm7ZEmY0px",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# these are stopwords and punctuation which is useless in our corpus so we should remove this\n",
        "\n",
        "print(list(stop_words))\n",
        "print(list(punctuation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W95fDprKY0qJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clean the imp column of  text by changing into simple words free from non-ascii converted into lower case \n",
        "\n",
        "from functools import reduce\n",
        "def _removeNonAscii(s): \n",
        "    return \"\".join(i for i in s if ord(i)<128)\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = text.replace('(ap)', '')\n",
        "    text = re.sub(r\"\\'s\", \" is \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r\"\\\\\", \"\", text)\n",
        "    text = re.sub(r\"\\'\", \"\", text)    \n",
        "    text = re.sub(r\"\\\"\", \"\", text)\n",
        "    text = re.sub('[^a-zA-Z ?!]+', '', text)\n",
        "    text = _removeNonAscii(text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1erQKcp8Y0qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# change the whole lines into tockens\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = clean_text(text)    \n",
        "    tokens = [word_tokenize(sent) for sent in sent_tokenize(text)]\n",
        "    tokens = (reduce(lambda x,y: x+y, tokens,[]))\n",
        "    tockens = tokens[:] \n",
        "    filtered_sentence = [w for w in tokens if not w in stop_words] \n",
        "    filtered_sentence = [] \n",
        "    for w in tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w) \n",
        "     \n",
        "    \n",
        "    \n",
        "    tokens = list(filter(lambda token: token not in (list(stop_words) + list(punctuation)) , tokens))\n",
        "    return filtered_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "13oj3RMvH6pe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AFIlyKHdY0q_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tockanize words of short_description free from stopwords punctuation \n",
        "\n",
        "data['tokens'] = data['imp'].progress_map(lambda d: tokenizer(d))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oxzIQfkY0rk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import feature column ate converted into tockens free from stopwords \n",
        "\n",
        "for descripition, tokens, category in zip(data['imp'].head(5), data['tokens'].head(5),data['category'].head(5)):\n",
        "    print('\\nimportant feature: ', descripition)\n",
        "    print('\\ntokens: ', tokens)\n",
        "    print('\\ncategory: ',category)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4FT9ILv_Y0sX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf-idf vectorization performed on tockenized dataset \n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(min_df=5, analyzer='word', ngram_range=(1,2), stop_words=stop_words)\n",
        "vx = vectorizer.fit_transform(list(data['tokens'].map(lambda tokens: ' '.join(tokens))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ToAgSlvY0s7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# shape of tf-idf sparse matrix\n",
        "\n",
        "vx.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z2pYYmcIY0tU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sparse matrix changed into array\n",
        "\n",
        "dense = vx.toarray()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7beUwlkakfQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dense.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iTW1jmmpa9EX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#to handle imbalance dataset i.e almost 38% of data are politics and entertainment use SMOTE oversampling method\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote=SMOTE(random_state=42)\n",
        "x,y=smote.fit_sample(dense,data['category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sJ8MC-2IcQ_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# After oversampling total no of data increases from 9996 to 82398\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJaWiynOcWRv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#now data get balanced having each class 3.22% of data\n",
        "d=pd.DataFrame(y)\n",
        "(d.groupby(by=0).size()/(y.shape))*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ur3ENbxAjvYQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
        "d[0].value_counts().plot.pie( autopct = '%1.1f%%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4cHR8FYgY0ti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# datasets is splitted into train and test \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "des_tr, des_te, cat_tr, cat_te = train_test_split(x,y,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qAT6HVf4Y0t5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset is fit on linear support vector\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "model = LinearSVC()\n",
        "model.fit(des_tr,cat_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14vMAfmGY0ub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prediction is made on test data and accuracy is calculate\n",
        "\n",
        "y_pred = model.predict(des_te)\n",
        "acc = accuracy_score(cat_te, y_pred)\n",
        "print(\"Accuracy {:.2f}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L11jcUh-fn1D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "print(classification_report(cat_te, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zl1_OQE3Y0u2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# these are 50 sample of actual value and predicted result on test data we can change range to get more sample\n",
        "# these results shows model doesn't predicted weird result even if wrong prediction is somewhat similar to actual \n",
        "\n",
        "p=np.asarray(cat_te)\n",
        "for x in range(5000,5050):\n",
        "    print(\"actual:\" ,cat_te[x] , \"           predicted:\" ,y_pred[x])\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCY9rV0CY0vR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# linear regression model is trained on the dataset and accuracy is calculated\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression()\n",
        "model.fit(des_tr,cat_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2I_651FZY0vy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(des_te)\n",
        "acc = accuracy_score(cat_te, y_pred)\n",
        "print(\"Accuracy {:.2f}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bU0ldPv_Y0wM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# multinominal naive baise model is fit and prediction is measured  \n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model=MultinomialNB()\n",
        "model.fit(des_tr,cat_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ZDNCviDY0wl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(des_te)\n",
        "acc = accuracy_score(cat_te, y_pred)\n",
        "print(\"Accuracy {:.2f}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}